<pre>
Tokenization is one of step which comes under data preprocessing pipeline.

Major usecase of tokenization is reduce the memory footprint for large text.

e.g.
Let us assume sample text is
"""Jack Ma -> If you donâ€™t do it, nothing is possible
   If you do it, at least, you have the hope that there's a chance."""
</pre>
